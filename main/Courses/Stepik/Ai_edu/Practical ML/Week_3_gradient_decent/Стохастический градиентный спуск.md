
**Вычислительные затраты градиентного спуска**

Градиентный спуск - численный метод, позволяющий искать минимумы различных,  даже очень сложных функций потерь. Однако для его реализации требуются большие вычислительные ресурсы.

Напомним, что на каждой итерации метода мы вычисляем градиент функции потерь:

$$∇𝑄(𝑤)=∑_{𝑖=1}^𝑙∇𝑞_𝑖(𝑤)$$
который равен сумме градиентов по всем объектам выборки.

Поэтому на каждой итерации градиентного спуска необходимо

- сделать много вычислений,  а именно,  вычислить значения 𝑙×𝑑 частных производных (где 𝑙 - число объектов, 𝑑d - число признаков)
- хранить эти вычисления в памяти

Обычно для сходимости требуются сотни или тысячи итераций.

Поэтому при больших размерах выборки и/или большом числе признаков градиентный спуск будет работать очень долго.