
метод опорных векторов можно применять для решения задач классификации, где в данных нет линейной зависимости.

**Новое признаковое пространство**

_Хорошим решением является создание нового набора признаков, в котором точки становятся линейно разделимыми. В новых признаках количество признаков может быть как больше, так и меньше, чем в исходных данных._

Сформулируем идею в виде алгоритма. 

Чтобы решить задачу бинарной классификации с нелинейно разделимыми данными, нужно:

1. подобрать нелинейное преобразование признаков: 𝑥→𝜑(𝑥)- такое, что в новом признаковом пространстве 𝜑(𝑥)данные станут линейно разделимыми;
2. обучить линейный классификатор на новых признаках 𝜑(𝑥).

**Ядровой метод опорных векторов** - это алгоритм, в котором:

- пользователь выбирает тип преобразования признаков (он задается функцией под названием _ядро_)
- линейный метод опорных векторов применяется к точкам в новом признаковом пространстве.

**Ядро**

С ядровым SVM тесно связано понятие ядра: давайте про него поговорим.

Пусть мы применили к признакам 𝑥 некоторое преобразование и получили признаки 𝜑(𝑥). 

Тогда ядро - это функция от двух аргументов 

𝐾(𝑎,𝑏)=(𝜑(𝑎),𝜑(𝑏)),

то есть значение ядра на объектах 𝑎 и 𝑏 (где каждый объект описывается исходными признаками) - это скалярное произведение векторов 𝜑(𝑎) и 𝜑(𝑏) в новом признаковом пространстве.

Зачем нам понадобилась некоторая новая функция 𝐾(𝑎,𝑏)?

Когда мы переходим в новое признаков пространство 𝑥→𝜑(𝑥), то формулы для предсказания модели и функции потерь также записываются в новых признаках. Однако новых признаков может быть очень много (например, из 10 признаков может получиться 10 000), что делает обучение и предсказание в новых признаках значительно более ресурсоёмким.

_Ядровой трюк_ позволяет решить эту проблему. Для некоторых моделей, в частности для SVM, предсказание модели и функцию потерь можно выразить через ядро 𝐾(𝑥). А это функция от исходных признаков, и, следовательно, обучение и предсказание будут занимать столько же времени, сколько и раньше, но при этом мы сможем решать задачи с нелинейной разделимостью.