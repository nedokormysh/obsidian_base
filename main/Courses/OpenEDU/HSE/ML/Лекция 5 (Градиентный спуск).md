
MSE для линейной регрессии:

$Q(w_1, ..., w_d)=\frac{1}{l}\sum\limits_{i=1}^l(w_1x_1 +... +w_dx_d - y_i)^2$

Про обучение линейной регрессии мы вывели аналитическую формулу для поиска весов. Но показали, что она не всегда применима. Если много признаков, или если используем другой функционал.

Другой подход решения.

- Градиент — вектор частных производных

$\nabla f(x) = (\frac{\partial f}{\partial x_1}, ..., \frac{\partial f}{\partial x_d})$

Это вектор, состоящий из частных производных, то есть мы берем нашу функцию какую-то от многих переменных, считаем частную производную по каждой из переменных, в нашем случае, например, если у нас d весов будет d переменных, от которых зависит ошибка, и составляем все эти частные производные в один вектор, который и называется градиентом

Условия экстремума:

- производная в точке экстремума равно нулю.
- в точке экстремума, если функция там дифференцируемы градиент равен нулю, ну, и отсюда возникает алгоритм для поиска всех экстремумов: записываем градиент, приравниваем нулю, решаем эту систему уравнений, берем все решения, которые получились, и смотрим, где значения функции поменьше, там и будет минимум

Бывают локальные и глобальные минимумы, и вот, если функционал, который мы минимизируем, выпуклый, вообще говоря строго выпуклый он должен быть, то минимум будет один, а функция называется выпуклой, если мы берем любые две точки на ее графике, соединяем их отрезком и график функции лежит ниже этого отрезка, вот тогда функция выпуклая.

Как мы решали раньше:

- брали градиент ошибки MSE, приравнивали нулю

$\nabla \frac{1}{l}||Xw-y||^2 = \frac{2}{l}X^T(Xw - y)$

Приравниваем нулю и решаем систему линейных уравнений:

$w=(X^TX)^{-1}X^Ty$

**Ещё одно важное свойство:**

- Зафиксируем точку x_0
- Функция быстрее всего растёт в сторону градиента
- А убывает быстрее всего в сторону антиградиента

Градиентный спуск:

- Стартуем из случайной точки
- Сдвигаемся по антиградиенту
- Повторяем пока не окажемся в точке минимума

Парная регрессия

- Простейший случай: один признак
- Модель: $a(x) = w_1x+w_0$
- Два параметра w_1 и w_0
- Функционал:

$Q(w_0, w_1)=\frac{1}{l}\sum\limits_{i=1}^l(w_1x_i + w_0 - y_i)^2$

$\frac{\partial Q}{\partial w_1} = \frac{2}{l} \sum\limits_{i=1}^l x_i(w_1x_i + w_0 - y_i)$

$\frac{\partial Q}{\partial w_0} = \frac{2}{l} \sum\limits_{i=1}^l (w_1x_i + w_0 - y_i)$

$\nabla Q(x) = \big(\frac{2}{l} \sum\limits_{i=1}^l x_i(w_1x_i + w_0 - y_i), \frac{2}{l} \sum\limits_{i=1}^l (w_1x_i + w_0 - y_i))$

Начальное приближение:

**Градиентный спуск:**

- нач. приближение

$w^0$ - инициализация весов

например, из стандартного нормального распределения.

- Повторяем до сходимости: $w^t = w^{t-1}-\eta \nabla Q(w^{t-1})$

Новая точка. Эта - шаг. Градиент в прошлой точке.

- Сходимость
    - останавливаем процесс, если
    
    $||w^t-w^{t-1}|| < \epsilon$
    
    - другой вариант
    
    $||\nabla Q(w^t)|| < \epsilon$
    

1) стартуем из случайной точки 2) двигаемся по антиградиенту 3) останавливаемся если в минимуме

Если признаков  d штук:

$Q(w)=\frac{1}{l}\sum\limits_{i=1}^l(<w, x> - y_i)^2$

$\frac{\partial Q}{\partial w_1} = \frac{2}{l} \sum\limits_{i=1}^l x_{i1}(<w, x> - y_i)$

…

$\frac{\partial Q}{\partial w_d} = \frac{2}{l} \sum\limits_{i=1}^l x_{id} (<w, x> - y_i)$

$\nabla Q(x) = \frac{2}{l} X^T(Xw-y)$

Проблемы:

Первая проблема, которую мы обсудим это проблема локальных минимумов. Локальным минимум называется точка, в некоторой окрестности которой нет более маленьких значений, а глобальный минимум называется просто самая низкая точка нашей функции.

Нам хотелось бы находить глобальный минимум, потому что там меньше ошибка модели, наверное, она более качественная, но вот не факт, что получится.

От близости начального приближения к глобальному минимуму зависит, попадём ли мы туда.

Градиентный спуск находит локальный минимум

Способы решения:

- мультистарт - запуск спуска из разных начальных точек. Всё равно можем не найти глобальный минимум, но шансов больше
- Длина шага - эта. Если градиент получился большим, то через некоторое время, то процесс поиска минимума будет расходится, т.е. функционал ошибки будет только увеличиваться с ростом количества итераций.
    - длина шага позволяет контролировать скорость обучения
    - если сделать скорость обучения недостаточно маленькой, то градиентный спуск может разойтись
    - длина шага - параметр, который нужно подбирать
    - переменная длина шага
        
        $w^t = w^{t-1} - \eta_t \nabla Q(w^{t-1})$
        
        Например:
        
        $\eta_t = \frac{1}{t}$
        
        Есть много вариантов, каким выбирать эту длину шага, например, единицы на t, то есть чем больше итераций мы сделали, тем медленнее мы шагаем. Это имеет
        смысл, в принципе, вот такая длина шага: в начале мы скорее всего находимся далеко от точки минимума, поэтому можно и как бы смело шагать подальше, а если номер итерации уже большой, скорее всего мы находимся где-то около минимума, и шаги можно замедлить.
        
        $\eta_t=\lambda (\frac{s}{s+t})^p$
        
        в таком виде не факт, что будет хорошо, то есть тут 1/t, никаких параметров, может быть в начале нужно вообще длину шага побольше иметь, 10, например, а вот тут конкретная скорость задаётся, на неё нельзя влиять, поэтому обычно используется вот второй вариант. Вот здесь больше параметров собственно, t - это все еще номер итерации, но есть s, который задает скорость в некотором смысле, есть лямбда который задает скорость в начале нашего процесса, и есть еще степень, которая тоже позволяет регулировать скорость убывания длины шага.
        

Ещё раз про масштабирование признаков:

Если признаки не масштабированы, то будем иметь вытянутые линии уровня. (например, один признак относительно мал, второй больше). И из-за этого градиент может сильно шатать. Градиент всегда направлен перпендикулярно линиям уровня.

Этого можно избежать, если масштабировать признаки, например, если бы признаки были не такие разнородные, если бы они были одного масштаба, то линии уровня были бы вот такими, и здесь градиентный спуск куда быстрее попал бы из начального приближения в точку минимума. Как масштабировать: один из вариантов - это вычесть из признака
среднее значение признака по всей выборке и поделить на стандартное отклонение.

**Стохастический градиентный спуск.**

- для вычисления градиента, как правило, нужно просуммировать что-то по всем объектам

Что если в выборке 1 млн объектов, чтобы сделать 1 маленький шаг.

Оценка градиента.

Функционал ошибки - среднее значение функции потерь на всех объектах

$Q(w) = \frac{1}{l}\sum \limits_{i=1}^l L(y_i, a(x_i))$

Градиент - это среднее значение градиентов всех отдельных слагаемых функции потерь на всех объектах обучающей выборки.

$\nabla Q(w) = \frac{1}{l}\sum \limits_{i=1}^l \nabla L(y_i, a(x_i))$  

Что если оценить градиент одним слагаемым.

$\nabla Q \approx\nabla L(y_i, a(x_i))$

Алгоритм: 

1) Начальное приближение $w^0$

2) Повторять каждый раз, выбирая случайным образом объект $i_t$

$w^t = w^{t-1}-\eta \nabla L(y_{i_t}, a(x_{i_t}) )$

3) Останавливаемся, если

$||w^t-w^{t-1}|| < \epsilon$

очень сильно штормит нашу траекторию, но и видно, что в конце процесс тоже очень плохо себя чувствует: мы не можем попасть в точку минимума и очень сильно шатаемся вокруг нее.

Это решается переменной длиной шага.

т.е. второй шаг

$w^t = w^{t-1}-\eta_t \nabla L(y_{i_t}, a(x_{i_t}) )$

Если посмотреть на график зависимости ошибки от номера итерации, тоже будет отлично видна разница между градиентным спуском и стохастическим градиентным спуском.  Ошибка вообще возрастает, потом она убывает довольно медленно, иногда там вверх чуть-чуть она подскакивает, в целом требуется куда больше итераций, чтобы достичь того же значения функционала ошибки как в полном градиентном спуске.

Но при этом в полном гранитном спуске мы суммируем по всем объектам обучающей
выборке градиенты на каждом шаге, а в стохастическом градиентном спуске каждый шаг
дико быстрый, мы там берем градиент всего для одного объекта,  поэтому скорее всего то, что нарисовано оранжевой кривой, хоть и занимает больше итерации по времени куда быстрее, чем полный градиентный спуск.

по одному объекту оценивать это вряд ли хорошая идея, поэтому есть модификация.

Есть модификация нашего градиентного спуска. mini-batch

1) Начальное приближение $w^0$

2) Повторять каждый раз, выбирая m случайных объектов $i_1, ... , i_m$

$w^t = w^{t-1}-\eta_t \frac{1}{m} \sum \limits_{j=1}^m \nabla L(y_{i_j}, a(x_{i_j}) )$ здесь не стали писать номер итерации, чтобы не нагромождать

3) Останавливаемся, если

$||w^t-w^{t-1}|| < \epsilon$

стохастический - более быстрый, но менее стабильный и требует выбора аккуратного шага

Ещё одно преимущество: он может позволять обучать нашу модель на выборках, которые не помещаются в оперативную память, мы можем иметь большой файл с нашей выборкой на жестком диске и читать по одной строчке из него. Считываем первый объект, считаем по нему градиент, делаем первый шаг стохастического градиентного спуска, забываем, читаем вторую строчку, делаем второй шаг, ну, и вот так можем ходить по циклу, по нашему файлу, читать по одному объекту или, например, по 10 объектов, по ним делать градиентный шаг и вот так продолжать, и тогда мы сможем обучить линейную модель даже на очень большой выборке.

**Функции потерь в задачах регрессии**

**СКО**

- частый выбор

$L(y, a) = (a-y)^2$

- функционал ошибки - собственно СКО

$Q(a,X)=\frac{1}{l}\sum\limits_{i=1}^l(a(x_i) - y_i)^2$

Даже из-за одного выброса получаем большую усреднённую ошибку.

Если мы немного модифицируем модель и сдвинем ее так, что она станет выдавать чуть более низкую ошибку на нашем выбросе. То есть за счет того, что мы испортили
модель на всех нормальных объектах, но немножко уменьшили ошибку на объекте
выброса, мы получили более низкое значение среднеквадратичной ошибки.

С точки зрения квадрата отклонения куда выгоднее уменьшить ошибку там, где она очень
большая, а вот увеличить немного ошибку там, где она маленькая, не очень страшно.
Получается, что выбросы важнее чем нормальные объекты.

Вариант решения проблемы:

**Средняя абсолютная ошибка MAE**

$L(y, a) = |a-y|$

- функционал ошибки - MAE

$Q(a,X)=\frac{1}{l}\sum\limits_{i=1}^l|a(x_i) - y_i|$

С точки зрения средней абсолютной ошибки у нас нет смысла портить прогнозы на
нормальных объектах чтобы сделать их поменьше на объекте выбросе. (Если мы ухудшаем модель и сдвигаем её чуть в сторону выброса, то ошибка возрастает, в отличии от СКО).
Поэтому средняя абсолютная ошибка куда лучше подходит для решения вот таких задач с зашумленными данными, с какими-то аномалиями. Но есть проблема: средняя абсолютная ошибка использует модуль, а у модуля, как вы помните, в нуле нет производной, поэтому нужно как-то ее модифицировать, чтобы можно было градиентный спуск использовать.

**Функция потерь Хубера**

$\begin{cases}
  \frac{1}{2} (y - a)^2, |y-a|<\delta\\
  \delta(|y-a|-\frac{1}{2}\delta),  |y-a|>=\delta
\end{cases}$

- функционал ошибки

$Q(a,X)=\frac{1}{l}\sum\limits_{i=1}^l L_H(y_i,a(x_i))$

Идея простая: там, где модуль отклонения y от а низкий, там где модуль y минус а меньше дельты, мы используем квадрат отклонения. То есть в районе нуля мы как бы параболу делаем, а там, где y от а отклоняется посильнее, мы используем что-то вроде модуля отклонения y минус а, которому там прибавили какую-то константу, точнее вычли какую-то константу, домножили на дельту.

функция потерь Хубера в итоге ведет себя как парабола возле 0 и как модуль чуть подальше от нуля

**MAPE средний модуль относительной ошибки**

может быть интересно узнать относительное отклонение нашего прогноза от факта, интересно понять, насколько мы сильно ошибаемся в масштабе наших данных

$L(y,a)=|\frac{y-a}{y}|$

$Q(a, X)=\frac{100\%}{l}\sum\limits_{i=1}^l|\frac{a(x_i) - y_i}{y_i}|$

допустим а меньше чем y, тогда легко заметить, что числитель будет всегда меньше знаменателя, и, естественно, наш штраф будет всегда не больше единицы.
А вот если а больше чем y, то вполне может оказаться, что штраф какой угодно: если растить а до плюс бесконечности, то штраф будет тоже расти не ограниченно. Получается, что с точки зрения модели всегда будет выгодно занижать прогноз, потому что если мы его занижаем, если а меньше чем y, то мы гарантируем, что штраф будет не больше единицы.

Особенности (при a ≥0):

- Недопрогноз штрафуется максимум на единицу
- Перепрогноз может быть оштрафован любым числом
- Несимметричная функция потерь (отдаёт предпочтение недопрогнозу)

Решение этой проблемы:

**SMAPE**

Symmetric Mean Absolute Percentage Error (симметричный средний модуль относительной ошибки)

$L(y,a)=\frac{|y-a|}{(|y|+|a|)/2}$

$Q(a, X)=\frac{100\%}{l}\sum\limits_{i=1}^l\frac{|y_i - a(x_i)|}{(|y_i|+|a(x_i)|)/2}$

значение этой функции потерь от 0 до 2: если мы хотим от 0 до 1, то можно было на два
поделить еще, и видно, что она везде ограничена двойкой независимо от того, куда мы идем от нашего истинного значения, здесь y тоже равен единице влево-вправо, больше двух штраф не станет. Ну, поэтому здесь уже как бы будут более-менее равные условия у недопрогноза и перепрогноза, и есть шанс, что модель не окажется смещенной при обучении на вот такую функцию потерь.

**Векторное дифференцирование.**

Пусть есть функция 

$f(x): ℝ^n \rightarrow ℝ$

$\nabla_x f(x):(\frac{\partial f(x)}{\partial x_1}, \frac{\partial f(x)}{\partial x_2}, ... , \frac{\partial f(x)}{\partial x_n})^T$ просто определили, что такое градиент

Пример 1. 

Пусть у нас есть функция.

$f(x)=a^Tx$ вектор параметров и вектор переменных. (т.е. обычное скалярное произведение, записанное в векторном виде.)

j - ая компонента градиента 

$\frac{\partial f(x)}{\partial x_j}= \frac{\partial (a_1x_1 + a_2x_2 + ... +a_nx_n)}{\partial x_j}= a_j$

$\nabla_x f(x)=(a_1, a_2,..., a_n)=a$

$\nabla_x a^Tx=a$

Пример 2.

Пусть есть матрица Anxn. Есть функция

$f(x)=x^TAx$

$\nabla_x x^TAx$-?

$\frac{\partial f(x)}{\partial x_i}= \frac{\partial}{\partial x_i}\sum\limits_j x_j(Ax)_j=\frac{\partial}{\partial x_i}\sum\limits_j x_j(\sum\limits_k a_{jk}x_k)=\frac{\partial}{\partial x_i}\sum\limits_{j,k} x_jx_ka_{jk}=\sum\limits_{j \neq i}a_{ji}x_j+\sum\limits_{k \neq i}a_{ik}x_k+2a_{ii}x_i = \sum\limits_j a_{ji}x_j + \sum\limits_k a_{ik}x_k$=

j и k равны

$=\sum\limits_j (a_{ji}+...+a{ij})x_j$

$\nabla_x x^TAx= (A+A^T)X$

**Регрессия в матричной форме**

${\{(x_i, y_i)\}}_1^L$

$x_i \in ℝ^d$ $y \in ℝ^1$

В общем виде у нас есть пары из объектов хi и ответов на них yi, всего у нас таких пар L штук.
Xi у нас точно так же как и ранее из Rd, у это у нас просто вещественные числа, R1, и мы хотим найти такие параметры у нашей модели а(x), которое у нас просто скалярное произведение w на x,

$a(x)=<w,x>$

такие параметры, чтобы у нас оптимизировалась наша функция ошибки, которая выглядит у нас как Q от а, Х по нашей выборке это 1 на L,

$Q(a,X)=\frac{1}{L}(y-Xw)^T(y-Xw)  \rightarrow \underset{w}{min}$

$X_{Lxd}$        

$y \in ℝ^L$

$w \in ℝ^d$

Х у нас размера L на d, у - это наш вектор ответов, собственно, он у нас размера L,
и w - это параметры нашей модели, w у нас Rd.

$\nabla_w Q(w) = \frac{1}{L} \nabla_w (y^Ty - y^T Xw-w^TX^Ty + w^T X^Tw)=$

Когда мы берем x на w транспонированное, они меняются местами оба становятся транспонированными.

$=\frac{1}{L}(0-X^Ty-X^Ty+(X^TX+(X^TX)^T)w)=$ 

$y^TX$ - это вектор (т.к. происходит умножение матрицы на вектор) поэтому у нас просто произведение этого вектора на вектор w скалярное.

Вспоминаем, что

$\nabla_x a^Tx=a$

$\nabla_w (y^TX)^Tw=X^Ty$

Нам нужно будет взять градиент от вектора $y^TX$ - это будет просто транспонирование.

Далее $X^Ty$ - тоже вектор. И получается, что третье слагаемое это опять умножение векторов.

Воспользуемся свойством:

$a^Tx=x^Ta$ здесь просто два произвольных вектора

$\nabla _x a^Tx=a$ следовательно

$\nabla _x x^Ta=a$

Подставим в наш случай $\nabla_w w^Ta=\nabla_w a^Tw=a= X^Ty$

$\nabla_w w^TX^Ty= X^Ty$ т.е. w^T просто уходит.

И последнее слагаемое. вектор w_T. на матрицу X^TX - это будет квадратная матрица размера dxd

$=\frac{2}{L}(-2X^Ty+2X^TXw)=\frac{2}{L}X^T(Xw-y)$

Если ищем минимум, то приравниваем нулю.

$X^Ty= X^TXw$

нам нужно найти веса. Для этого мы можем слева умножить на x транспонированное x в минус первой степени, то есть мы умножаем на х транспонированное х минус 1,то есть это обратная матрица на х транспонированное y, это слагаемое у нас уходит, то есть веса, как было показано на функции, будут равны вот такой вот формуле .

$(X^TX)^{-1}X^Ty=w$

**Градиентный спуск в матричной форме.**

$w^0$ - начальные веса.

$w^t=w^{(t-1)}-\mu_t\nabla_wQ(w^{(t-1)})$

$||w^t-w^{(t-1)}||_2<\epsilon$

$\nabla_wQ(w^{(t-1)})=\frac{2}{L}X^T(Xw^{(t-1)}-y)$

обновление весов в матричной форме:

$w^t=w^{(t-1)}-\eta_t \frac{2}{L}X^T(Xw^{(t-1)}-y)$

У нас есть сложность, за которую мы можем эту операцию проводить, она у нас зависит от
количества наших признаков d и от количества наших объектов. Сложность у нас - О от L умножить на d, это если мы используем полный градиентный спуск

$O(Ld)$ - полный градиентный спуск

$O(dk)$ - стохастический градиентный спуск

[[OpenEDU_HSE_ML_Content]] [[00_ML]]