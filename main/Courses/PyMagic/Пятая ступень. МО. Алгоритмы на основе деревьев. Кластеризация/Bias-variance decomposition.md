Дано (задача регрессии):
$𝑋 = (𝑥_l , 𝑦_l)_{i=1}^l$ – обучающая выборка размером 𝑙
$𝐿(𝑦, 𝑎) = (𝑦 − 𝑎 (𝑥) )^2$ - квадратичная функция потерь
$𝑄(𝑎)$ – качество (усреднение ошибки)
$𝔼 [𝑧] = \frac{Σ_{i=1}^Nz_i}{N}$ – краткая запись матожидания
Решение:
$𝑄(𝑎) = 𝔼[(𝑦 − 𝑎 𝑥 )^2] = 𝔼[𝑦^2] + 𝔼[𝑎(𝑥)^2] − 2𝔼[𝑦𝑎(𝑥) ] = 𝔼[𝑦^2] + 𝔼[ \hat{𝑦}^2] − 2𝔼[𝑦 \hat{𝑦}]$
В силу линейности математического ожидания справедлива формула для дисперсии по свойству мат ожидания:
$𝐷[𝑋] = 𝑉𝑎𝑟[𝑋] = 𝔼[𝑋 − (𝔼[𝑋])^2$
$𝔼[𝑋^2] = 𝑉𝑎𝑟(𝑋) + (𝔼[𝑋])^2$

Пропустил вывод формулы
$𝑸(𝒂) = 𝔼[𝑦^2] + 𝔼[ \hat{𝑦}^2] − 2𝔼[𝑦\hat{𝑦}]= 𝑩𝒊𝒂𝒔 (\hat{𝒚}^2)+ 𝑽𝒂𝒓 (\hat{𝒚}) + 𝝈^𝟐$

**Смещение (bias)**
Показывает, насколько хорошо с помощью данного метода обучения и семейства алгоритмов можно приблизить оптимальный алгоритм.
Сгенерируем несколько обучающих выборок и обучим модели. Смещением называется отклонение среднего ответа на основании обученных моделей $𝔼[\hat{𝑦} ]$ от ответа идеального алгоритма 𝑓.

**Дисперсия (variance)**
Показывает, насколько сильно может изменяться ответ обученного алгоритма в зависимости от выборки — иными словами, она характеризует чувствительность метода обучения к изменениям в выборке.
Сгенерируем несколько обучающих выборок и обучим модели. Разброс ответов у данных моделей и будет являться дисперсией.

**Шум**
Неустранимый шум в данных


## Влияние бэггинна на ошибку. Bias

Дано (задача регрессии):
$𝑋 = (𝑥_l , 𝑦_l)_{i=1}^l$ – обучающая выборка размером 𝑙
$𝑋_1, 𝑋_2,…, 𝑋_N$ – подвыборки размера 𝑙 сгенерированные при помощи бутстрэпа с возвращением
$𝑏_1(𝑥) , 𝑏_2(𝑥) ,…, 𝑏_n(𝑥)$ – базовые алгоритмы обученные на подвыборках
$a(𝑥)$ – обученный алгоритм на подвыборках
$𝑗 = 1,…,𝑁$ – кол-во подвыборок, соответственно также базовых алгоритмов
Решение:
$$𝑎(𝑥) =\frac{1}{𝑁}\sum_{i=1}^Nb_j(x)$$
1) Перезапишем матожидание (среднее) в сокращенную форму:
$$𝔼[𝑎(𝑥)] = 𝔼[ \hat{𝑦}]$$
2) Вспоминаем, что смещением называется отклонение среднего ответа на основании моделей от ответа идеального
алгоритма:
$$𝐵𝑖𝑎𝑠(\hat{𝑦})^2 =(𝑓(x) − 𝔼[\hat{𝑦}])^2$$
3) Тогда распишем более подробно нашу формулу с помощью суммы базовых алгоритмов:
$$𝐵𝑖𝑎𝑠(\hat{𝑦})^2 =(𝑓(x) − 𝔼[\hat{𝑦}])^2 = (𝑓 (x)- 𝔼[\frac{1}{𝑁}\sum_{i=1}^Nb_j(x)])^2=(𝑓 (x)- \frac{1}{𝑁}\sum_{i=1}^N𝔼[b_j(x)])^2=Bias(a(x))^2$$
Получили, что смещение композиции равно смещению одного алгоритма

## Влияние бэггинга на ошибку. Var


Решение:
1) Распишем дисперсию
𝜎% =
Σ&'(
) (𝑋& − '
𝑋
)%
𝑁
= 𝔼 𝑋 − 𝔼𝑋 %
𝑉𝑎𝑟 𝑋 = 𝔼 𝑋% − (𝔼[𝑋])%
2) Распишем наш разброс при помощи 𝑉𝑎𝑟 𝑋 и распишем 0𝑦 через сумму базовых алгоритмов, вынесем за скобки постоянный множитель в
силу свойства линейности матожидания
𝑉𝑎𝑟 0𝑦 = 𝔼 0𝑦 − 𝔼[ 0𝑦 ]% = 𝔼
1
𝑁
3
*'(
)
𝑏* 𝑥 − 𝔼
1
𝑁
3
*'(
)
𝑏* 𝑥
%
=
1
𝑁% 𝔼 3
*'(
)
𝑏* 𝑥 − 𝔼 3
*'(
)
𝑏* 𝑥
%
3) Раскроем скобки (вспоминаем из школы, что квадрат суммы равен сумме квадратов + их удвоенное произведение)
𝑉𝑎𝑟 0𝑦 = ⋯ =
1
𝑁% 𝔼 3
*'(
)
𝑏* 𝑥 − 𝔼𝑏* 𝑥
%
=
1
𝑁%3
*'(
)
𝔼 𝑏* 𝑥 − 𝔼𝑏* 𝑥 % +
1
𝑁%3
&+*
)
𝔼 2 𝑏& 𝑥 − 𝔼𝑏& 𝑥 9 𝑏* 𝑥 − 𝔼𝑏* 𝑥
4) Второе слагаемое есть нечто иное как ковариация между базовыми алгоритмами
𝑉𝑎𝑟 0𝑦 = ⋯ =
1
𝑁%3
*'(
)
𝑉𝑎𝑟(𝑏* 𝑥 ) +
2
𝑁%3
&+*
)
𝑐𝑜𝑣 𝑏& 𝑥 , 𝑏* 𝑥
5) Если предположить, что базовые алгоритмы некоррелированы, так как использовали бутстрэп (ковариация равна 0), то:
𝑽𝒂𝒓 A𝒚 =
𝟏
𝑵𝟐3
𝒋'𝟏
𝑵
𝑽𝒂𝒓(𝒃𝒋 𝒙 ) =
𝟏
𝑵
𝑽𝒂𝒓(𝒃𝟏 𝒙 )
Получилось, что в этом случае дисперсия композиции в 𝑵 раз меньше дисперсии отдельного алгоритма

• Смещение (bias) – показывает, насколько хорошо с помощью данного метода обучения и семейства алгоритмов можно приблизить оптимальный алгоритм.
• Дисперсия (variance) – показывает, насколько сильно может изменяться ответ обученного алгоритма в зависимости от выборки — иными словами, она
характеризует чувствительность метода обучения к изменениям в выборке.
• Маленькое смещение у сложных семейств (например, у деревьев) и большое у простых семейств (например, линейных классификаторов)
• Простые семейства имеют маленькую дисперсию, а сложные семейства — большую дисперсию. Поэтому подбор модели это всегда также компромисс, между двумя составляющими.

## Summary
• Ошибка для обученного алгоритма раскладывается на шум, смещение и разброс
• Параллельное обучение (бэггинг) на сгенерированных подвыборках при помощи
бутстрэпа позволяет снизить дисперсию ошибки в N раз, где N - кол-во базовых
алгоритмов (уменьшение в N раз, если базовые алгоритмы некоррелированы)
• Ситуация с уменьшением дисперсии ошибки в реальном мире не такая идеальная,
потому что объекты в наших подвыборках будут все равно пересекаться (получим
коррелированые модели), в конечном итоге мы не можем бесконечно добавлять
базовые алгоритмы
• Смещение базового алгоритма совпадает со смещением композиции из базовых
алгоритмов. Бэггинг не влияет на смещение.

[[RandomForest. Бутстрэп. Бэггинг]]