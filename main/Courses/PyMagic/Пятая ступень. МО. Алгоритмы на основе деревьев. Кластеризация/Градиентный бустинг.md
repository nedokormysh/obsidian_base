

Случайные леса не всегда применимы, так как нам необходимо строить глубокие переобученные деревья независимо друг от друга, а потом объединять ответ по ним,
это ведет к большим временным затратам и ресурсам, если мы будем ограничивать их снизу, то тогда можем упустить некоторые закономерности.
Поэтому, если у вас многомиллионная выборка и много признаков, то данный алгоритм плохо применим. Чтобы решить сложную задачу, также потребуется большое количество деревьев.
Бустинг позволяет решить вышеизложенные проблемы, так как:
• Последовательно обучает базовые алгоритмы
• Строит алгоритмы на основании предыдущей ошибки (минимизация ошибки)
• Достаточно простых базовых неглубоких алгоритмов


# Бустинг

Бустинг — это процедура последовательного построения композиции алгоритмов машинного обучения, когда каждый следующий алгоритм стремится компенсировать недостатки композиции всех предыдущих алгоритмов.
Бустинг представляет собой жадный алгоритм построения композиции алгоритмов
$𝑎(𝑥) = \sum_{n=1}^N𝑏_n(𝑥)$

# Градиентный бустинг. Общий алгоритм
Дано:
𝑿 – матрица объект-признаки (train)
𝒚 – целевая переменная (train)
𝑙 – кол-во объектов в обучающей выборке
𝑎 – базовый алгоритм
$\frac{1}{l}∑_{i=1}^{l}(𝑦_i − 𝑎(𝑥_i ))^2→ min$
Функционал для минимизации (MSE)

1) 𝑿, 𝒚
Сначала обучим первый базовый алгоритм $𝑏_1(𝑥)$ , который наилучшим образом
приближает целевую переменную.
Построенный алгоритм  $𝑏_1(𝑥)$, скорее всего, работает не идеально.
$$𝒃_1(𝒙) = 𝒂𝒓𝒈𝒎𝒊𝒏_{𝒃∈𝑨}\frac{1}{2}\sum_{i=1}^l(𝒚_𝒊 − 𝒂(𝒙_𝒊))^𝟐$$

2) $𝑿, 𝒚 - 𝒃_𝟏(𝒙)$

$$𝒃_2(𝒙) = 𝒂𝒓𝒈𝒎𝒊𝒏_{𝒃∈𝑨}\frac{1}{2}\sum_{i=1}^l(s_𝒊^{(1)} − 𝒂(𝒙_𝒊))^𝟐$$

Поэтому, чтобы учесть ошибку предыдущего алгоритма, вычислим, насколько сильно отличаются предсказания $𝑏_1(𝑥)$ от истинных значений 𝑦 (сдвиг): $𝒔_𝒊^{(𝟏)} = 𝒚_𝒊 − 𝒃_𝟏(𝒙_𝒊)$
Обучим на основании сдвига $𝑏_2(𝑥)$. Ожидается, что композиция из двух таких моделей $𝒂_𝟐(𝒙) = 𝒃_𝟏(𝒙) + 𝒃_𝟐(𝒙)$ будет лучше предсказывать целевую переменную 𝒚
3)   $𝑿, 𝒚 - \sum_{n=1}^N𝒃_n(𝒙_i)$


$$𝒃_2(𝒙) = 𝒂𝒓𝒈𝒎𝒊𝒏_{𝒃∈𝑨}\frac{1}{2}\sum_{i=1}^l(s_𝒊^{(N)} − 𝒂(𝒙_𝒊))^𝟐$$

Каждый следующих алгоритм будем аналогично строить по остаткам предыдущего

$$s_i^{(N)}=y_i - \sum_{n=1}^{N-1}b_n(x_i)=y_i - a_{N-1}(x_i), i=1,...,l$$
## Градиент

$$L(y,x)=\frac{1}{2}\sum_{i=1}^l(y_i-a(x_i))^2 \rightarrow min$$



Найдем от выражения выше производную от 𝑎_k алгоритма, предположим, что до этого мы уже обучили 𝑘 − 1 алгоритмов


$$\frac{\partial L(y_i,z)}{\partial z}\Bigg|_{z=a_k(x_i)}=\frac{\partial }{\partial z}\frac{1}{2}(y_i-z)^2\Bigg|_{z=a_k(x_i)}=-(y_i-z)\Bigg|_{z=a_k(x_i)}=a_k(x_i)-y_i$$
Вектор сдвигов
$$s_i^{(N)}=-\frac{\partial L(y_i,z)}{\partial z}\Bigg|_{z=a_k(x_i)}=y_i-a_k(x_i)$$
где
$$a_k(x_i)=\sum_{k=1}^Nb_k(x_i)$$
Поэтому каждый следующий алгоритм в бустинге обучается предсказывать антиградиент функции потерь по предсказанию модели
Общая формула для вектора сдвига, без привязки к функции потерь



$$s=-\nabla{F(s)}=\Big(-L'(y_1,b(x_1)),..., -L'(y_l,b(x_l))\Big)$$
## Алгоритм подробно

1) В качестве примера будем минимизировать квадратичную ошибку (обычно берут дерево решений – базовый алгоритм)
$\frac{1}{l}∑_{i=1}^l(𝑦_i − 𝑎(𝑥_i ))^2→ min_a$

2) Строим первый базовый алгоритм 𝑏_1(𝑥)
$$𝒃_1(𝒙) = 𝒂𝒓𝒈𝒎𝒊𝒏_{𝒃∈𝑨}\frac{1}{2}\sum_{i=1}^l(𝒚_𝒊 − 𝒂(𝒙_𝒊))^𝟐$$
3) Теперь мы хотим построить следующий базовый алгоритм 𝒃_𝟐(𝒙_𝒊) , но как учесть предыдущую ошибку алгоритма и на основании нее обучить новый? Пусть сумма ответов на наших алгоритмах равна истинному значению целевой переменной 
$𝑏_1(𝑥_i) + 𝒃_𝟐(𝒙_𝒊) = 𝑦_i$
Тогда будем обучать второй алгоритм на основании ошибки предыдущего
$𝒃_𝟐(𝒙_𝒊) = 𝑦_i − 𝑏_1(𝑥_i)$
Обозначается как вектор сдвига: $𝑠_i^{(N)} = 𝑦_i − 𝑏_1(𝑥_i)$

$$𝒃_2(𝒙) = 𝒂𝒓𝒈𝒎𝒊𝒏_{𝒃∈𝑨}\frac{1}{2}\sum_{i=1}^l(s_i^{1}-a(x_i))^2=𝒂𝒓𝒈𝒎𝒊𝒏_{𝒃∈𝑨}\frac{1}{2}\sum_{i=1}^l(𝒚_𝒊 − b_1(𝒙_𝒊)-a(x_i))^𝟐$$


4) Каждый следующих алгоритм будем аналогично строить по остаткам предыдущего 

$$s_i^{(N)}=y_i - \sum_{n=1}^{N-1}b_n(x_i)=y_i - a_{N-1}(x_i), i=1,...,l$$



$$𝒃_n(𝒙) = 𝒂𝒓𝒈𝒎𝒊𝒏_{𝒃∈𝑨}\frac{1}{2}\sum_{i=1}^l(s_i^{(N)}-a(x_i))^2=𝒂𝒓𝒈𝒎𝒊𝒏_{𝒃∈𝑨}\frac{1}{2}\sum_{i=1}^l\Big(\Big(𝒚_𝒊 − \sum_{n=1}^{N-1}b_n(x_i)\Big)-a(x_i)\Big)^𝟐$$

Итог:
Итоговый ответ при обучении алгоритмов на основании ошибок предыдущих


$$a_N(x_i)=\sum_{n=1}^Nb_n(x_i)$$

## Регуляризация

1) Сокращение шага
Обучение композиции с помощью градиентного бустинга может привести к переобучению, если базовые алгоритмы слишком сложные.
Например, если сделать решающие деревья слишком глубокими (глубина > 10), то при обучении бустинга ошибка на обучающей выборке даже при довольно небольшом кол-ве базовых алгоритмов 𝑁 может приблизиться к нулю, то есть train будет почти идеальным, но на test всё будет плохо.

Существует два решения этой проблемы:
1) Упростить базовую модель, уменьшив глубину дерева (либо примерив техники регуляризации)
2) Ввести параметр – темп обучения learning rate 𝜂 ∈ (0,1]
$$𝑎_N(𝑥) = 𝑎_{N-1}(𝑥) + 𝜼𝑏_N(𝑥) = 𝑏_1(𝑥) + 𝜼𝑏_2(𝑥) + ⋯+ 𝜼𝑏_N(𝑥)$$
learning rate – гиперпараметр, который необходимо подбирать. Чем меньше шаг, тем больше нужно базовых алгоритмов


2) Стохастический градиентный бустинг
Помимо того, что мы применяем общее (глобальное) значение learning rate ко всем алгоритмам, давайте также учитывать скорость обучения на каждом шаге, который будет зависеть от конкретного базового алгоритма 𝜸𝑵:

$$𝑎_N(𝑥) = 𝑎_{N-1}(𝑥) + 𝜼𝜸_𝑵𝑏_N(𝑥)$$

$$𝜸_𝑵=argnmin_𝜸{\sum_{i=1}^lL(y_i, a_{N-1}(x_i)+𝜼𝜸𝑏_N(𝑥_i))}$$

3) Использование регуляризаторов
Вспомним про применение регуляризации для линейных моделей, которая помогала нам бороться с переобучением за счет упрощения модели
$$𝑄(𝑤, 𝑋) + 𝜆\sum_{j=1}^d𝑤_j^2 → min_w$$
Такой же подход можем применить для нашего градиентного бустинга, для разных модификаций могут использовать разные регуляризаторы. Теперь представим, что наша целевая функция, которую необходимо минимизировать состоит также из двух частей:

$$ 𝑜𝑏𝑗(𝜃)= \sum_{i=1}^N𝐿(𝑦_i, 𝑎_{N-1}x_i + 𝜂𝑏_N(𝑥_i)) + \sum_{k=1}^K Ω 𝑓_k$$
Второе слагаемое можем расписать как сумму разных регуляризаторов (выводится при помощи аппроксимации функции второго порядка

$$Ω(𝑓)= 𝛾𝑇 +\frac{1}{2}𝜆\sum_{j=1}^T𝑤_j^2 + 𝛼\sum_{i=1}^T|w_i|$$

𝛾 – штрафует модель за большое кол-во листьев 𝑇. Остальные – контролируют сумму предсказаний модели в листьях
(𝑤 – веса, отношение кол-ва объектов в левом/правом поддереве от вершины к общему кол-ву объектов в вершине).
Чем больше листьев имеет дерево, тем сложнее его разделяющая поверхность, тем больше у него параметров и тем выше риск переобучения.

## Гиперпараметры
* num_iterations (n_estimators) – кол-во базовых алгоритмов (деревьев), фиксируем данный параметр самым первым шагом (от 100 до 300), чтобы подобрать скорость обучения
* learning_rate (eta) – скорость обучения (0,1]. Подбираем после n_estimators
𝜶 - alpha / 𝝀 - lambda / 𝜸 - gamma – коэффициенты регуляризации
* max_depth – максимальная глубина дерева (от 4 до 10)
* subsample – доля объектов, на которых строится дерево для предотвращения переобучения (0,1]. В этом случае градиентный бустинг называется стохастическим. В sklearn подвыборки выбираются без возвращения
* colsample_bytree / max_features – доля признаков, на которых обучается дерево на каждом этапе разбиения (0,1], также max_features может быть задан {‘auto’, ‘sqrt’, ‘log2’}
* min_samples_leaf – минимальное количество объектов в листовой ноде, после которого не нужно делать разбиение int: [1, inf), float: (0,1]
* min_samples_split – минимальное количество объектов для разбиение в узле int: [2, inf), float: (0,1]


# Бустинг vs Бэггинг

1) Оба алгоритма используют N базовых классификаторов
• Бустинг использует последовательное обучение
• Бэггинг использует параллельное обучение
2) Оба пытаются уменьшить ошибку:
• Бэггинг может решить проблему переобучения, путем уменьшения дисперсии
• Бустинг пытается уменьшить смещение (underfitting), но может увеличить проблему переобучения

## Бустинг
Плюсы:
• Не накапливает ошибку на каждом базовом алгоритме, как это может быть в случайном лесе
• Позволяет точно восстанавливать искомую функцию
Минусы:
• Может переобучаться (когда избыток базовых алгоритмов, либо глубокие деревья)
• Плохо интерпретируется (если сравнивать с простым деревом)
• Нужна большая обучающая выборка

# Представители

[[Xgboost]]
[[LightGBM]]
[[]]



[[Пятая ступень. МО. Композиции. Кластеризация._Content]] [[Pymagic_Content]] [[00_ML]]