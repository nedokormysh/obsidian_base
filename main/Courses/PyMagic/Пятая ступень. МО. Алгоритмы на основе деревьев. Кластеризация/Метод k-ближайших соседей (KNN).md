
Метрические алгоритмы также могут использоваться в задачах классификации и
регрессии, но они немного отличаются от деревьев и линейных алгоритмов, так как
ориентируется по расстоянию между объектами.

Классификация
Объекту присваивается тот класс, который является наиболее распространён среди k соседей данного элемента, метки которых уже известны.
Синий – тренировочный образец 1го класса
Красный – тренировочный образец 2го класса
Зеленый – тестовый образец
Первый круг захватывает k=3 ближайших соседей, в данном случае больше объектов в виде треугольников красного цвета, значит объект с вопросом будет предсказан как красный треугольник. Второй круг захватывает k=5, в этом случае неизвестному объект будет предсказан как синий квадрат.
Регрессия
Объекту присваивается среднее значение по k ближайшим к нему объектам, значения
которых уже известны.


# Алгоритм (классификация):
1. Выбрать число k соседей и метрику расстояния
2. Использовать метрику расстояния, чтобы получить расстояние между train и test точками
3. Отсортировать вычисленные расстояния, чтобы найти точки, ближайшие к test (ближайшие соседи)
4. Присвоить метку класса мажоритарным голосованием
5. Повторяйте шаги с 1 по 4, пока не будут классифицированы все точки test данных
Важно:
• Модель KNN очень восприимчива к переобучению из-за явления проклятия размерности, когда пространство признаков становится все более разреженным
• Интуитивно можно представить, что ближайшие соседи (объекты) находятся в высокоразмерном
пространстве слишком далеко, чтобы дать хорошую оценку
• Также разные признаки могут иметь разный диапозон значений в выборке, например, признак возраст
находится в диапозоне от 23 до 80, а признак зарплата от 20000 до 500000, из за этого значения дистанции
могут сильно зависеть от атрибутов с бо́льшими диапазонами
Поэтому необходимо нормализовать данные. Используют MinMaxScalar