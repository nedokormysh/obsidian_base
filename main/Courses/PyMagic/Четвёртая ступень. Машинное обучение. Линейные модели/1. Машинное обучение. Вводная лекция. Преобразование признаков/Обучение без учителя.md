Когда мы в своем наборе можем иметь только данные объекты-признаки, задачу можно свести к обучению без учителя, так как у нас нет ответов, на которых алгоритм может обучаться. И мы должны понять, как нам наши объекты разбить на группы по схожим признакам.

# Кластеризация

Мы группируем объекты по неким схожим признакам. Но здесь есть одно, но, нам не
известно, сколько, может быть, подобных групп – кластеров, чтобы приблизительно
оценить их число, используют специальные метрики, которые мы будем проходить
далее.

# Снижение размерности для сжатия данных

Когда мы имеем данные высокой размерности, то часто нам необходимо их сжать, чтобы снизить нагрузку на память (объем и производительность) при вычислениях. Подход на основе снижения размерности без учителя широко используется во время предобработки признаков с целью удаления из данных шума, который тоже может ухудшить предсказательную способность некоторых алгоритмов, и для сжатия данных в подпространство меньшей размерности при сохранении большей части релевантной информации. Иногда снижение размерности может быть полезно для визуализации данных - например, высокоразмерный набор признаков может быть спроецирован на одно-, двух- или трехмерные пространства признаков с целью их визуализации при помощи трех- или двухмерных точечных графиков или гистограмм.

# Поиск аномалий

В задаче требуется определять, что данный объект не похож на все остальные, при обучении есть только примеры не аномальных объектов, а примеров аномальных либо нет вообще, либо очень мало. 

[[Введение в МО]]