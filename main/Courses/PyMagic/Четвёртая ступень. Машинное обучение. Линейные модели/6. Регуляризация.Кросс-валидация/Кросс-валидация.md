
## Кросс-валидация. K-Fold

Один из методов для обнаружения переобучения. Обычно число фолдов k=5 или 10. K-fold это вычислительно затратный способ, поэтому его обычно применяют когда:
- Данных мало
- Есть большие вычислительные ресурсы
Алгоритм:
1) Исходная выборка разбивается на k блоков одинакового
размера, перед этим может перемешиваться случайно
2) Проходим по циклу с 1 по k раз:
1) Возьмем блок с индексом i как test, а оставшиеся k-1 блоков
как train
2) Обучим алгоритм на train выборке, измерим качество на
test выборке, запомним значение метрики
3) После того, как каждый блок поучаствовал в качестве тестового,
находим среднее значение метрики по всем итерациям – это и будет
средняя оценка качества по кросс-валидации – OOF (out-of-fold).


## Кросс-валидация со стратифицированной выборкой. StratifiedKFold

Метод подобен предыдущему рассмотренному примеру, но здесь в каждом из K-блоков соблюдается соотношение классов какое оно было изначально.
Используется часто при дисбалансе классов, так как простая кросс- валидация может упустить в одном из блоков недостающий класс.
Подходит для задачи классификации.


## Кросс-валидация с перемешиванием ShuffleSplit

Метод подобен K-Fold, но выборки каждый раз перемешиваются, а затем разделяются на train и test. Тестовые выборки могут пересекаться при обучении на каждой из ступеней.


## Кросс-валидация с перемешиванием. StratifiedShuffleSplit


Метод подобен StratifiedKFold + ShuffleSplit.

Выборки каждый раз перемешиваются, а затем разделяются на train и test, но обязательно соблюдается соотношение классов какое оно было изначально.
Тестовые выборки могут пересекаться при обучении на каждой из ступеней.

[[Регуляризация. Кросс-валидация. Поиск параметров]]