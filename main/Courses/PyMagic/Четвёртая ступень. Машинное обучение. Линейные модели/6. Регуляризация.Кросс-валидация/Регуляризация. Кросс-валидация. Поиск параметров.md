
# Регуляризация

* **Overfitting** – переобучение, происходит в результате чрезмерной подгонки параметров модели к зависимостям, содержащимся в обучающем множестве.
Ошибка на тестовой выборке значительно больше, чем на тренировочной.
* **Underfitting** – недообучение, если наша модель наоборот, очень простая и не до конца хорошо описывает данные. Часто это про то, что ошибка достаточно большая на тренировочных данных.

[[Bias-variance decomposition]]
# Борьба с переобучением

Признак переобучения большими значениями коэффициентов. Добавить ограничение на коэффициенты модели – штрафы.

- Использование регуляризации
- Выбор наиболее подходящей модели. Например, если у нас есть линейная зависимость
между признаками и целевой переменной
- Увеличение кол-ва набора данных
- Подбор гиперапараметров модели
- Использование ранней остановки (в бустингах)
- Обрезка алгоритмов на основании деревьев
- Проверка исходного датасета (лики в данных, например, не удалили ID)

[[Регуляризация]]


# Оценка работы алгоритма

## Hold-out validation
Обычно принято разбивать train/test в соотношении train 70% и test 30%,чаще train 80% и test 20%.
Также важно не забывать про семплирование и стратификацию для задачи классификации.
## Train validation test
Соотношение примерено train 64% / validation 16%/ test 20%.
Validation данные используются для настройки алгоритмов ML, а именно позволяют отслеживать момент переобучения и далее производить раннюю остановку обучения алгоритма.
Test данные (Holdout) необходимы для объективной, честной оценки работы нашего алгоритма

[[Кросс-валидация]]


[[Поиск параметров по сетке]]

[[Четвёртая ступень. МO. Лин мод._Content]] [[Pymagic_Content]]  [[00_ML]] 