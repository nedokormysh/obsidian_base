Мы не можем знать изначально, какие параметры алгоритма дадут лучшие результаты для той или иной задачи на конкретных данных.
Поэтому, нам необходимо сделать некоторый перебор значений гиперпараметров, чтобы на каждом таком наборе смотреть метрики, и далее уже выбирать тот набор параметров, где заданная метрика максимальна.

GridSearch. Перебираем все наборы значений друг с другом.
RandomizedSearch Перебираем НЕ все наборы параметров, а только часть случайных наборов.

Байесовская оптимизация
Значения параметров алгоритма выбираются с учетом результатов на предыдущем шаге.
Байесовская оптимизация – это модификация случайного (стохастического) поиска за одним
исключением, в данном виде оптимизации мы учитываем предыдущие шаги.
Строим вероятностную модель целевой функции и используем ее для поиска оптимальных
параметров.
Библиотеки: Hyperopt, Optuna
