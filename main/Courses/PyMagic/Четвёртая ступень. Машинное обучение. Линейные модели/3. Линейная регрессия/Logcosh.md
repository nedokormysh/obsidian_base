Logcosh – функция ошибки Лог-Кош, используется логарифм гиперболического косинуса. Применяется как функция потерь (лосс) в задаче регрессии
$$logcosh = \sum_{i=1}^n log(cosh(y_i-a(x_i))$$

В окрестности нуля имеет график параболы, а при больших значения аргумента она линейна, то есть устойчива к выбросам
• Не нужно подбирать гиперпараметр как в Huber loss
• Второй порядок Logcosh незначителен, но все же проблемы могут возникнуть
Например, если ошибка велика, градиент и гессиан (для метода ньютона) станут фиксированными, что приведет к отсутствию точек разделения в XGBoost.
htps://ru.wikipedia.org/wiki/Гессиан_функции

[[Линейная регрессия]]