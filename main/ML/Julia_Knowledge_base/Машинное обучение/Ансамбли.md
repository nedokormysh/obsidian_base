# Ансамбли

- Здесь обозначу, что точно стоит понимать про ансамбли.
Руководство к действию - открыть табличку, пробежаться глазами, понять, что все эти тонкости помнишь, закрыть табличку.
    
    
    | **Идея:**
    использовать все имеющиеся модели и при этом получить на тестовых данных качество выше, чем могла показать каждая из этих моделей в отдельности |
    | --- |
    | Рассматриваем функционал, который используем для оценки качества работы алгоритма.
    Обозначим Q(a).
    Для него существует разложение на шум, смещение и разброс. (**bias-variance decomposition**)
    
    **смещение (bias)** предсказания алгоритма в точке x, усреднённого по всем возможным обучающим выборкам, относительно истинной зависимости f
    
    **дисперсия (разброс)** предсказаний алгоритма в зависимости от обучающей выборки X
    
    и еще остается неустранимый **шум** в данных |
    | Далее всё основывается на идее минимизации смещения без увеличения разброса и минимизации разброса без увеличения смещения (на шум мы не можем никак повлиять) |
    | Б**эггинг** (**bagging**, **bootstrap aggregation**) |
    | Пусть обучающая выборка состояла из n объектов. Выберем из неё n
    примеров равновероятно, с возвращением. Получим новую выборку X1, в которой некоторых элементов исходной выборки не будет, а какие-то могут войти несколько раз. С помощью некоторого алгоритма b обучим на этой выборке модель b1(x)=b(x,X1). Повторим процедуру: сформируем вторую выборку X2 из n элементов с возвращением и с помощью того же алгоритма обучим на ней модель b2(x)=b(x,X2). Повторив процедуру k раз, получим k моделей, обученных на k выборках. Чтобы получить одно предсказание, усредним предсказания всех моделей. |
    | Процесс генерации подвыборок с помощью семплирования с возвращением называется **бутстрепом** (**bootstrap**) |
    | В этом случае смещение композиции равно смещению одного алгоритма |
    | В этом случае дисперсия (разброс) композиции в k раз меньше дисперсии отдельного алгоритма. (действует в предположении, что алгоритмы не скоррелированны между собой) |
    | **Random forest** |
    | Построим ансамбль алгоритмов, где базовый алгоритм — это решающее дерево. |
    | **1.** Для построения i-го дерева:
    а. Сначала, как в обычном бэггинге, из обучающей выборки X выбирается с возвращением случайная подвыборка X_i того же размера, что и X.
    
    б. В процессе обучения каждого дерева в каждой вершине случайно выбираются n<N признаков, где N — полное число признаков (метод случайных подпространств), и среди них ищется оптимальный сплит. Такой приём как раз позволяет управлять степенью скоррелированности базовых алгоритмов.
    
    **2.** Чтобы получить предсказание ансамбля на тестовом объекте, усредняем отдельные ответы деревьев (для регрессии) или берём самый популярный класс (для классификации).
    **3.** Profit. Мы построили Random Forest (случайный лес) – комбинацию бэггинга и метода случайных подпространств над решающими деревьями. |
    | **Глубина деревьев**
    В случайном лесе используем **глубокие деревья.**
    
    У неглубоких деревьев малое число параметров, то есть дерево способно запомнить только верхнеуровневые статистики обучающей подвыборки. Они во всех подвыборках будут похожи, но будут не очень подробно описывать целевую зависимость |
    | **Число признаков**
    Практическая рекомендация – брать корень из числа всех признаков для классификации и треть признаков для регрессии. |
    | **Число деревьев**
    имеет смысл построить график ошибки от числа деревьев и ограничить размер леса в тот момент, когда ошибка перестанет значимо уменьшаться. |
    | **Boosting** |
    | строится множество базовых алгоритмов из одного семейства, объединяющихся затем в более сильную модель
    Отличие состоит в том, что в бэггинге и случайном лесе базовые алгоритмы учатся независимо и параллельно, а в бустинге – последовательно
    
    Каждый следующий базовый алгоритм в бустинге обучается так, чтобы уменьшить общую ошибку всех своих предшественников. |
    | Итоговая композиция будет иметь меньшее смещение, чем каждый отдельный базовый алгоритм (хотя уменьшение разброса также может происходить). |
    | Если в качестве базовых классификаторов выступают деревья, то их глубина должна быть небольшой – обычно не больше 2-3 уровней, так как работаем с моделями с высоким смещением и небольшим разбросом. |
    | Ещё одной важной причиной для выбора моделей с высоким смещением в качестве базовых является то, что такие модели, как правило, быстрее учатся. Это важно для их последовательного обучения, которое может стать очень дорогим по времени, если на каждой итерации будет учиться сложная модель. |
    | **Стекинг** |
    | алгоритм ансамблирования, основные отличия которого от предыдущих состоят в следующем:
    **1.** он может использовать алгоритмы разного типа, а не только из какого-то фиксированного семейства. Например, в качестве базовых алгоритмов могут выступать метод ближайших соседей и линейная регрессия
    **2.** результаты базовых алгоритмов объединяются в один с помощью обучаемой мета-модели, а не с помощью какого-либо обычного способа агрегации (суммирования или усреднения) |
    | Обучение стекинга проходит в несколько этапов:
    
    1. общая выборка разделяется на тренировочную и тестовую
    2. тренировочная выборка делится на n фолдов. Затем эти фолды перебираются тем же способом, что используется при кросс-валидации: на каждом шаге фиксируются (n−1) фолдов для обучения базовых алгоритмов и один – для их предсказаний (вычисления мета-факторов). Такой подход нужен для того, чтобы можно было использовать всё тренировочное множество, и при этом базовые алгоритмы не переобучались
    3. на полученных мета-факторах обучается мета-модель. Кроме мета-факторов, она может принимать на вход и фичи из исходного датасета. Выбор зависит от решаемой задачи |
    | Для получения мета-факторов на тестовом множестве базовые алгоритмы можно обучить на всём тренировочном множестве – переобучения в данном случае возникнуть не должно. |
    | Если данных достаточно много, то можно просто разделить обучающие данные на две непересекающиеся части: ту, на которой учатся базовые алгоритмы, и ту, на которой они делают свои предсказания и обучается мета-модель. Использование такого простого разбиения вместо кросс-валидации на тренировочных данных иногда называют **блендингом (blending)**. Если данных совсем много, то тестовое множество тоже можно разделить на две части: тестовую и валидационную, и использовать последнюю для подбора гиперпараметров моделей-участников |
    | С точки зрения смещения и разброса стекинг не имеет прямой интерпретации, так как не минимизирует напрямую ни ту, ни другую компоненту ошибки. Удачно работающий стекинг просто уменьшает ошибку, и, как следствие, её компоненты тоже будут убывать. |