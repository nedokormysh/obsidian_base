# Метрические алгоритмы

- Здесь обозначу, что точно стоит понимать про метрические алгоритмы.
Руководство к действию - открыть табличку, пробежаться глазами, понять, что все эти тонкости помнишь, закрыть табличку.

| **KNN**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
| -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| *Многоклассовая классификация:*<br>    Берем k ближайших (в смысле расстояния) объектов с известным таргетом. Для нового объекта предсказание - наиболее встречающийся класс среди этих k. Важно, что можем оценивать вероятности классов - это просто частоты встречаемых классов среди k ближайших объектов.                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| Легко переобучается - при маленьких k алгоритм легко подстраивается под конкретные данные.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| Расстояние может быть:<br>    - евклидово<br>    - манхэттенская метрика<br>    - метрика минковского <br>    - косинусное расстояние <br>    - расстояние Жаккара <br>    и тд                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| **Взвешенный KNN**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| *как появилось?*<br>    никак не обрабатывали сами расстояния до объектов. Хотим увеличивать вклад близких и уменьшать вклад далеких. Добавляем веса в индикаторы вхождения объекта в k ближайших.<br>    <br>*как выбирать веса?*<br>    - пусть зависят от порядкового номера объекта в отсортированном по близости массиве. Чаще всего берем либо линейно, либо экспоненциально затухающие веса<br>    - можем функцию от самих весов - kernel function<br>    *требования к функции:<br>    она должна быть положительной на своей области определения, иначе модель будет поощрять несовпадение с некоторыми ближайшими соседями. Также необходимо, чтобы функция монотонно не возрастала, чтобы вес близких соседей был больше, чем далёких.*                  |
| **В задаче регрессии**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| Идея: можем брать среднее (взвешенное среднее) от k ближайших соседей                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| *Плюсы KNN*<br>    <br>    - Непараметрический, то есть не делает явных предположений о распределении данных.<br>    - Очень простой в объяснении и интерпретации.<br>    - Достаточно точный, хоть и чаще всего уступает градиентному бустингу и случайному лесу в accuracy.<br>    - Может быть использован как для классификации, так и для регрессии.<br>    <br>*Минусы KNN*<br>    <br>    - Неэффективный по памяти, поскольку нужно хранить всю обучающую выборку.<br>    - Вычислительно дорогой по той же причине.<br>    - Чувствителен к масштабу данных, а также к неинформативным признакам.<br>    - Для применения алгоритма необходимо, чтобы метрическая близость объектов совпадала с их семантической близостью, чего не всегда просто добиться. |
| **Поиск соседей**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|  Методы делятся на точные и приближенные. <br>    Точные - k-d деревья<br>    Приближенные - random projection trees, LSH, HNSW                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
[[Машинное обучение]]